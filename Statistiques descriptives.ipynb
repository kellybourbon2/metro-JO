{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ddf45ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelly\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'data.ratp.fr'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\kelly\\AppData\\Local\\Temp\\ipykernel_15176\\854636992.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"Traffic\"], subset_df[\"Station\"] = subset_df[\"Station\"].copy(), subset_df[\"Traffic\"].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Traffic_Per_Day   LIBELLE_ARRET  0H-1H  10H-11H  11H-12H  12H-13H  \\\n",
      "0               4147        ABBESSES     79      157      198      235   \n",
      "1               8488          ALESIA     92      396      452      562   \n",
      "2               7026    ALMA-MARCEAU    189      168      226      360   \n",
      "3               6333  ANATOLE FRANCE     38      319      355      391   \n",
      "4              11205          ANTONY     32      603      665      748   \n",
      "..               ...             ...    ...      ...      ...      ...   \n",
      "209             9825        VILLIERS    118      431      524      677   \n",
      "210            15133       VINCENNES    150      677      787      913   \n",
      "211             4753     VOLONTAIRES     36      264      292      329   \n",
      "212             9463        VOLTAIRE    155      441      502      564   \n",
      "213             4133          WAGRAM     31      210      245      288   \n",
      "\n",
      "     13H-14H  14H-15H  15H-16H  16H-17H  ...  23H-0H  2H-3H  3H-4H  4H-5H  \\\n",
      "0        249      291      337      373  ...     136      0    0.0    0.0   \n",
      "1        579      595      635      666  ...     121      1    0.0    0.0   \n",
      "2        349      376      490      651  ...     350      0    0.0    0.0   \n",
      "3        382      414      442      480  ...      69      0    0.0    0.0   \n",
      "4        698      697      714      816  ...     144      0    0.0   11.0   \n",
      "..       ...      ...      ...      ...  ...     ...    ...    ...    ...   \n",
      "209      634      642      699      782  ...     233      1    0.0    0.0   \n",
      "210      897      894      983     1181  ...     243      1    0.0    4.0   \n",
      "211      317      343      355      353  ...      64      0    0.0    0.0   \n",
      "212      597      623      678      712  ...     247      0    0.0    0.0   \n",
      "213      287      281      298      322  ...      66      0    0.0    0.0   \n",
      "\n",
      "     5H-6H  6H-7H  7H-8H  8H-9H  9H-10H  ND  \n",
      "0        9     31     78    196     193 NaN  \n",
      "1       24     82    257    612     503 NaN  \n",
      "2       22     45     98    226     215 NaN  \n",
      "3       27     66    181    439     388 NaN  \n",
      "4      127    318    737   1019     672 NaN  \n",
      "..     ...    ...    ...    ...     ...  ..  \n",
      "209     27     63    185    492     511 NaN  \n",
      "210    134    270    613   1112     832 NaN  \n",
      "211     20     54    145    317     310 NaN  \n",
      "212     50    115    245    584     555 NaN  \n",
      "213     15     36     96    223     236 NaN  \n",
      "\n",
      "[214 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "#On s'occupe d'abord de nettoyer les données sur le nombre de validation par jour à partir des données annuelles\n",
    "url = \"http://data.ratp.fr/explore/dataset/trafic-annuel-entrant-par-station-du-reseau-ferre-2021/download?format=csv&timezone=Europe/Berlin&use_labels_for_header=false\"\n",
    "response = requests.get(url, verify=False)\n",
    "df = pd.read_csv(StringIO(response.text), sep=';', header=None)\n",
    "df.columns = [\"ID\", \"Type\", \"Station\", \"Traffic\", \"Col4\", \"Col5\", \"Col6\", \"Col7\", \"Col8\", \"City\", \"Col10\"]\n",
    "subset_df = df[[\"Traffic\", \"Station\"]]\n",
    "subset_df[\"Traffic\"], subset_df[\"Station\"] = subset_df[\"Station\"].copy(), subset_df[\"Traffic\"].copy()\n",
    "subset_df.columns = [\"Station\", \"Traffic\"]\n",
    "subset_df = subset_df.iloc[1:].reset_index(drop=True)\n",
    "# Créer un nouveau tableau avec la somme du trafic pour chaque station\n",
    "sum_traffic_df = subset_df.groupby(\"Station\")[\"Traffic\"].sum().reset_index()\n",
    "sum_traffic_df[\"Traffic\"] = pd.to_numeric(sum_traffic_df[\"Traffic\"], errors='coerce')\n",
    "# Diviser le trafic par 365 pour chaque station pour avoir le trafic par jour\n",
    "sum_traffic_df[\"Traffic_Per_Day\"] = (sum_traffic_df[\"Traffic\"] / 365).astype(int)\n",
    "\n",
    "\n",
    "#On s'occupe ensuite de nettoyer les données sur la répartition de l'affluence sur une journée\n",
    "%config NotebookApp.iopub_data_rate_limit=100000000000.0\n",
    "url = 'validations-reseau-ferre-profils-horaires-par-jour-type-1er-semestre (1).csv'\n",
    "données_validation= pd.read_csv(url)\n",
    "données_validation = pd.read_csv(url, delimiter=';')\n",
    "données_validation_station_horaire = données_validation[['LIBELLE_ARRET', 'TRNC_HORR_60','pourc_validations']]\n",
    "donnees_organisees = données_validation_station_horaire.pivot_table(index='LIBELLE_ARRET', columns='TRNC_HORR_60', values='pourc_validations', aggfunc='mean').reset_index()\n",
    "\n",
    "#On fusionne les données des deux tableaux pour avoir le nombre de validation sur chaque plage horaire\n",
    "merged_df = pd.merge(sum_traffic_df, donnees_organisees, left_on='Station', right_on='LIBELLE_ARRET')\n",
    "columns_to_multiply = donnees_organisees.columns[1:]\n",
    "resultat = merged_df.copy()\n",
    "resultat[columns_to_multiply] = resultat[columns_to_multiply].multiply(resultat['Traffic_Per_Day'], axis=0)\n",
    "resultat[columns_to_multiply] = resultat[columns_to_multiply].div(100)\n",
    "resultat = resultat.iloc[:, 2:]\n",
    "# Sélectionner les colonnes numériques\n",
    "numeric_columns = resultat.select_dtypes(include='number').columns\n",
    "resultat[numeric_columns] = resultat[numeric_columns].applymap(lambda x: int(x) if pd.notna(x) else x)\n",
    "print(resultat)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
