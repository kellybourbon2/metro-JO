{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ddf45ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelly\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'data.ratp.fr'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\kelly\\AppData\\Local\\Temp\\ipykernel_18624\\2276804303.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[\"Traffic\"], subset_df[\"Station\"] = subset_df[\"Station\"].copy(), subset_df[\"Traffic\"].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LIBELLE_ARRET     0H-1H    10H-11H    11H-12H    12H-13H    13H-14H  \\\n",
      "0          ABBESSES  1.316667   2.616667   3.300000   3.916667   4.150000   \n",
      "1            ALESIA  1.533333   6.600000   7.533333   9.366667   9.650000   \n",
      "2      ALMA-MARCEAU  3.150000   2.800000   3.766667   6.000000   5.816667   \n",
      "3    ANATOLE FRANCE  0.633333   5.316667   5.916667   6.516667   6.366667   \n",
      "4            ANTONY  0.533333  10.050000  11.083333  12.466667  11.633333   \n",
      "..              ...       ...        ...        ...        ...        ...   \n",
      "209        VILLIERS  1.966667   7.183333   8.733333  11.283333  10.566667   \n",
      "210       VINCENNES  2.500000  11.283333  13.116667  15.216667  14.950000   \n",
      "211     VOLONTAIRES  0.600000   4.400000   4.866667   5.483333   5.283333   \n",
      "212        VOLTAIRE  2.583333   7.350000   8.366667   9.400000   9.950000   \n",
      "213          WAGRAM  0.516667   3.500000   4.083333   4.800000   4.783333   \n",
      "\n",
      "       14H-15H    15H-16H    16H-17H    17H-18H  ...   22H-23H    23H-0H  \\\n",
      "0     4.850000   5.616667   6.216667   6.633333  ...  2.600000  2.266667   \n",
      "1     9.916667  10.583333  11.100000  11.250000  ...  2.933333  2.016667   \n",
      "2     6.266667   8.166667  10.850000  13.050000  ...  6.050000  5.833333   \n",
      "3     6.900000   7.366667   8.000000   9.833333  ...  1.583333  1.150000   \n",
      "4    11.616667  11.900000  13.600000  15.366667  ...  3.150000  2.400000   \n",
      "..         ...        ...        ...        ...  ...       ...       ...   \n",
      "209  10.700000  11.650000  13.033333  14.100000  ...  4.533333  3.883333   \n",
      "210  14.900000  16.383333  19.683333  24.816667  ...  4.916667  4.050000   \n",
      "211   5.716667   5.916667   5.883333   6.766667  ...  1.650000  1.066667   \n",
      "212  10.383333  11.300000  11.866667  13.066667  ...  4.433333  4.116667   \n",
      "213   4.683333   4.966667   5.366667   6.250000  ...  1.400000  1.100000   \n",
      "\n",
      "        2H-3H  3H-4H     4H-5H     5H-6H     6H-7H      7H-8H      8H-9H  \\\n",
      "0    0.000000    0.0  0.000000  0.150000  0.516667   1.300000   3.266667   \n",
      "1    0.016667    0.0  0.000000  0.400000  1.366667   4.283333  10.200000   \n",
      "2    0.000000    0.0  0.000000  0.366667  0.750000   1.633333   3.766667   \n",
      "3    0.000000    0.0  0.000000  0.450000  1.100000   3.016667   7.316667   \n",
      "4    0.000000    0.0  0.183333  2.116667  5.300000  12.283333  16.983333   \n",
      "..        ...    ...       ...       ...       ...        ...        ...   \n",
      "209  0.016667    0.0  0.000000  0.450000  1.050000   3.083333   8.200000   \n",
      "210  0.016667    0.0  0.066667  2.233333  4.500000  10.216667  18.533333   \n",
      "211  0.000000    0.0  0.000000  0.333333  0.900000   2.416667   5.283333   \n",
      "212  0.000000    0.0  0.000000  0.833333  1.916667   4.083333   9.733333   \n",
      "213  0.000000    0.0  0.000000  0.250000  0.600000   1.600000   3.716667   \n",
      "\n",
      "        9H-10H  \n",
      "0     3.216667  \n",
      "1     8.383333  \n",
      "2     3.583333  \n",
      "3     6.466667  \n",
      "4    11.200000  \n",
      "..         ...  \n",
      "209   8.516667  \n",
      "210  13.866667  \n",
      "211   5.166667  \n",
      "212   9.250000  \n",
      "213   3.933333  \n",
      "\n",
      "[214 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "#On s'occupe d'abord de nettoyer les données sur le nombre de validation par jour à partir des données annuelles\n",
    "url = \"http://data.ratp.fr/explore/dataset/trafic-annuel-entrant-par-station-du-reseau-ferre-2021/download?format=csv&timezone=Europe/Berlin&use_labels_for_header=false\"\n",
    "response = requests.get(url, verify=False)\n",
    "df = pd.read_csv(StringIO(response.text), sep=';', header=None)\n",
    "df.columns = [\"ID\", \"Type\", \"Station\", \"Traffic\", \"Col4\", \"Col5\", \"Col6\", \"Col7\", \"Col8\", \"City\", \"Col10\"]\n",
    "subset_df = df[[\"Traffic\", \"Station\"]]\n",
    "subset_df[\"Traffic\"], subset_df[\"Station\"] = subset_df[\"Station\"].copy(), subset_df[\"Traffic\"].copy()\n",
    "subset_df.columns = [\"Station\", \"Traffic\"]\n",
    "subset_df = subset_df.iloc[1:].reset_index(drop=True)\n",
    "# Créer un nouveau tableau avec la somme du trafic pour chaque station\n",
    "sum_traffic_df = subset_df.groupby(\"Station\")[\"Traffic\"].sum().reset_index()\n",
    "sum_traffic_df[\"Traffic\"] = pd.to_numeric(sum_traffic_df[\"Traffic\"], errors='coerce')\n",
    "# Diviser le trafic par 365 pour chaque station pour avoir le trafic par jour\n",
    "sum_traffic_df[\"Traffic_Per_Day\"] = (sum_traffic_df[\"Traffic\"] / 365).astype(int)\n",
    "\n",
    "\n",
    "#On s'occupe ensuite de nettoyer les données sur la répartition de l'affluence sur une journée\n",
    "%config NotebookApp.iopub_data_rate_limit=100000000000.0\n",
    "url = 'validations-reseau-ferre-profils-horaires-par-jour-type-1er-semestre (1).csv'\n",
    "données_validation= pd.read_csv(url)\n",
    "données_validation = pd.read_csv(url, delimiter=';')\n",
    "données_validation_station_horaire = données_validation[['LIBELLE_ARRET', 'TRNC_HORR_60','pourc_validations']]\n",
    "donnees_organisees = données_validation_station_horaire.pivot_table(index='LIBELLE_ARRET', columns='TRNC_HORR_60', values='pourc_validations', aggfunc='mean').reset_index()\n",
    "\n",
    "#On fusionne les données des deux tableaux pour avoir le nombre de validation sur chaque plage horaire\n",
    "merged_df = pd.merge(sum_traffic_df, donnees_organisees, left_on='Station', right_on='LIBELLE_ARRET')\n",
    "columns_to_multiply = donnees_organisees.columns[1:]\n",
    "resultat = merged_df.copy()\n",
    "resultat[columns_to_multiply] = resultat[columns_to_multiply].multiply(resultat['Traffic_Per_Day'], axis=0)\n",
    "resultat[columns_to_multiply] = resultat[columns_to_multiply].div(100)\n",
    "resultat = resultat.iloc[:, 2:]\n",
    "numeric_columns = resultat.select_dtypes(include='number').columns\n",
    "resultat[numeric_columns] = resultat[numeric_columns].applymap(lambda x: int(x) if pd.notna(x) else x)\n",
    "numeric_columns = resultat.select_dtypes(include='number').columns\n",
    "\n",
    "# Créer un nouveau tableau avec l'affluence divisée par minute pour chaque plage horaire\n",
    "affluence_par_minute_df = resultat.copy()\n",
    "affluence_par_minute_df[numeric_columns] = affluence_par_minute_df[numeric_columns].div(60)\n",
    "# Supprimer la colonne 'ND'\n",
    "affluence_par_minute = affluence_par_minute_df.drop(columns=['ND'])\n",
    "# Supprimer la première colonne\n",
    "affluence_par_minute = affluence_par_minute.drop(affluence_par_minute.columns[0], axis=1)\n",
    "\n",
    "# Afficher le nouveau tableau\n",
    "print(affluence_par_minute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33ea6bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de personnes entrant à 10.23 à la station ALESIA: 6.6\n"
     ]
    }
   ],
   "source": [
    "def nombre_personnes_entrant(horaire, station):\n",
    "    # Convertir l'horaire en minutes\n",
    "    horaire_en_minutes = int(horaire.split('.')[0]) * 60 + int(horaire.split('.')[1])\n",
    "\n",
    "    # Trouver la plage horaire correspondante dans le tableau\n",
    "    plage_horaire = None\n",
    "    for col in affluence_par_minute.columns[1:]:\n",
    "        debut, fin = map(int, col.replace('H', '').split('-'))\n",
    "        debut_en_minutes = debut * 60\n",
    "        fin_en_minutes = fin * 60 if fin != 0 else 24 * 60  # Si la fin est 0H, utiliser 24H\n",
    "\n",
    "        # Vérifier si l'horaire est dans la plage horaire actuelle\n",
    "        if debut_en_minutes <= horaire_en_minutes < fin_en_minutes:\n",
    "            plage_horaire = col\n",
    "            break\n",
    "\n",
    "    # Si la plage horaire est trouvée, rechercher la station en utilisant une correspondance partielle\n",
    "    if plage_horaire:\n",
    "        matching_station = affluence_par_minute['LIBELLE_ARRET'].str.contains(station, case=False)\n",
    "        if matching_station.any():\n",
    "            return affluence_par_minute.loc[matching_station, plage_horaire].values[0]\n",
    "\n",
    "    # Retourner None si la plage horaire ou la station n'est pas trouvée\n",
    "    return None\n",
    "\n",
    "# Exemple d'utilisation\n",
    "horaire_entree = \"10.23\"\n",
    "station_entree = \"ALESIA\"\n",
    "nombre_entrant = nombre_personnes_entrant(horaire_entree, station_entree)\n",
    "print(f\"Nombre de personnes entrant à {horaire_entree} à la station {station_entree}: {nombre_entrant}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
