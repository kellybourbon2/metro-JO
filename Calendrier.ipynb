{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tabula\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lieux = [\n",
    "'stade-tour-eiffel',\n",
    "'arena-champ-de-mars',\n",
    "'grand-palais',\n",
    "'invalides',\n",
    "'pont-alexandre-iii',\n",
    "'trocadero', \n",
    "'concorde',\n",
    "'stade-roland-garros',\n",
    "'arena-paris-sud', \n",
    "'arena-bercy', \n",
    "'arena-la-chapelle', \n",
    "'paris-la-defense-arena', \n",
    "'centre-aquatique', \n",
    "'stade-de-france',\n",
    "'site-escalade-bourget',\n",
    "'arena-paris-nord'\n",
    "]\n",
    "\n",
    "vecteur = [lieux[0] if i < 4 else\n",
    "           lieux[1] if i < 8 else\n",
    "           lieux[2] if i < 13 else\n",
    "           lieux[3] if i < 15 else\n",
    "           lieux[4] if i < 17 else\n",
    "           lieux[5] if i < 19 else\n",
    "           lieux[6] if i < 29 else\n",
    "           lieux[7] if i < 35 else\n",
    "           lieux[8] if i < 48 else\n",
    "           lieux[9] if i < 58 else\n",
    "           lieux[10] if i < 63 else\n",
    "           lieux[11] if i < 68 else\n",
    "           lieux[12] if i < 74 else\n",
    "           lieux[13] if i < 78 else\n",
    "           lieux[14] if i < 79 else\n",
    "           lieux[15] if i < 83 else\n",
    "           'Valeur par défaut' for i in range(83)]\n",
    "\n",
    "\n",
    "# Lien vers le PDF contenant le tableau\n",
    "lien_pdf = \"https://medias.paris2024.org/uploads/2022/07/Calendrier-par-epreuves-des-Jeux-Olympiques-de-Paris-2024.pdf\"\n",
    "\n",
    "try : \n",
    "    # Utilisation de tabula pour extraire le tableau du PDF\n",
    "    # Utilisation de l'option 'pages' pour spécifier la page ou les pages contenant le tableau\n",
    "    df_list = tabula.read_pdf(lien_pdf, pages=[1, 2], stream=True)  # Adapter les options selon vos besoins\n",
    "\n",
    "    # Concaténer les DataFrames obtenus des différentes pages en un seul DataFrame\n",
    "    df = pd.concat(df_list)\n",
    "\n",
    "    # Supprimer les 28 dernières lignes\n",
    "    df = df.iloc[:-32]\n",
    "    df.drop(24, inplace=True)\n",
    "    df.drop(23, inplace=True)\n",
    "    df.drop(55, inplace=True)\n",
    "\n",
    "    # Supprimer la première ligne du DataFrame\n",
    "    df = df.drop(df.index[[0, 2]])  # Suppression de la première ligne\n",
    "    df = df.drop(df.columns[[0]], axis=1)\n",
    "\n",
    "    # Supprimer les lignes contenant uniquement des NaN\n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    df.columns = df.iloc[0]\n",
    "    df.drop(1, inplace=True)\n",
    "\n",
    "    df.index = vecteur\n",
    "    \n",
    "    df = df.replace('<', np.nan)\n",
    "\n",
    "except Exception as e:\n",
    "        print(\"Une erreur s'est produite :\", str(e))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "def format_date_horaire(cell, index_value):\n",
    "    if isinstance(cell, str) and '-' in cell:\n",
    "        date_month = '07' if int(index_value) in range(24, 32) else '08'\n",
    "        year = '2024'\n",
    "        \n",
    "        date = f\"{index_value}/{date_month}/{year}\"\n",
    "        horaire1, horaire2 = cell.split('-')\n",
    "        \n",
    "        return f\"{date} {horaire1.strip()} - {horaire2.strip()}\"\n",
    "    else:\n",
    "        return cell\n",
    "\n",
    "# Appliquer la fonction à chaque cellule du DataFrame\n",
    "for column in df.columns:\n",
    "    df[column] = df.apply(lambda x: format_date_horaire(x[column], column), axis=1)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Supprimer les titres des index\n",
    "df.index.name = None\n",
    "\n",
    "# Ajouter Lieux pour la première colonne\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = ['Lieux'] + list(df.columns[1:])  # Renommer la première colonne en 'Lieux'\n",
    "\n",
    "# %%\n",
    "# Créer un dictionnaire pour stocker les valeurs non vides associées à chaque lieu\n",
    "data = {}\n",
    "for idx, row in df.iterrows():\n",
    "    lieu = row['Lieux']\n",
    "    if lieu not in data:\n",
    "        data[lieu] = []\n",
    "\n",
    "    # Récupérer les valeurs non vides et les ajouter à la liste des valeurs du lieu\n",
    "    values = row.drop('Lieux').dropna().tolist()\n",
    "    data[lieu].extend(values)\n",
    "\n",
    "# Créer un nouveau DataFrame à partir du dictionnaire\n",
    "new_df = pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "lieux_a_supprimer = ['arena-paris-nord', 'site-escalade-bourget', 'centre-aquatique']\n",
    "\n",
    "# Suppression des lignes spécifiées\n",
    "new_df = new_df.drop(lieux_a_supprimer, axis=0)\n",
    "\n",
    "# %%\n",
    "# Fonction pour convertir le format de date\n",
    "def convert_date_format(entry):\n",
    "    if isinstance(entry, str):\n",
    "        parts = entry.split(' ')\n",
    "        if len(parts) == 5:\n",
    "            date = parts[0]\n",
    "            start_time = parts[1]\n",
    "            return f\"{date} {start_time}\"\n",
    "    return entry\n",
    "\n",
    "# Appliquer la fonction sur toutes les colonnes du DataFrame\n",
    "for col in new_df.columns:\n",
    "    new_df[col] = new_df[col].apply(convert_date_format)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Appliquer une fonction pour supprimer la partie après le tiret dans chaque cellule\n",
    "horaires_début = new_df.applymap(lambda x: x.split(' -')[0] if isinstance(x, str) else x)\n",
    "\n",
    "# Appliquer une fonction pour supprimer les 4 caractères avant le tiret dans chaque cellule\n",
    "horaires_fin = new_df.applymap(lambda x: pd.Series(x).replace(r'.{5}\\s-\\s', '', regex=True)[0] if isinstance(x, str) else x)\n",
    "\n",
    "horaires_début = horaires_début.applymap(lambda x: pd.to_datetime(x, errors='coerce'))\n",
    "horaires_début = horaires_début.dropna(axis=1, how='all')\n",
    "\n",
    "horaires_fin = horaires_fin.applymap(lambda x: pd.to_datetime(x, errors='coerce'))\n",
    "horaires_fin = horaires_fin.dropna(axis=1, how='all')\n",
    "\n",
    "# Afficher le DataFrame résultant\n",
    "display(horaires_début)\n",
    "display(horaires_fin)\n",
    "\n",
    "\n",
    "# %%\n",
    "def adjust_time_moins_90min(cell):\n",
    "    # Vérifier si la cellule est vide ou non\n",
    "    if not pd.isnull(cell):\n",
    "        # Convertir la cellule en objet datetime\n",
    "        cell = pd.to_datetime(cell, format='%d/%m/%Y %H:%M')\n",
    "        # Ajouter 1 heure et 30 minutes à l'objet datetime\n",
    "        cell = cell - pd.Timedelta(hours=1, minutes=30)\n",
    "    return cell\n",
    "\n",
    "def adjust_time_plus_30min(cell):\n",
    "    # Vérifier si la cellule est vide ou non\n",
    "    if not pd.isnull(cell):\n",
    "        # Convertir la cellule en objet datetime\n",
    "        cell = pd.to_datetime(cell, format='%d/%m/%Y %H:%M')\n",
    "        # Retirer 30 minutes à l'objet datetime\n",
    "        cell = cell + pd.Timedelta(hours=0, minutes=30)\n",
    "    return cell\n",
    "\n",
    "# Parcourir chaque cellule du DataFrame et appliquer la fonction adjust_time\n",
    "new_horaires_début_df = horaires_début.map(adjust_time_moins_90min)\n",
    "new_horaires_fin_df = horaires_fin.map(adjust_time_plus_30min)\n",
    "\n",
    "new_horaires_début_df.reset_index(inplace=True)\n",
    "new_horaires_début_df.rename(columns={'index': 'Lieu'}, inplace=True)\n",
    "\n",
    "new_horaires_fin_df.reset_index(inplace=True)\n",
    "new_horaires_fin_df.rename(columns={'index': 'Lieu'}, inplace=True)\n",
    "\n",
    "display(new_horaires_début_df)\n",
    "display(new_horaires_fin_df)\n",
    "\n",
    "new_horaires_fin_df.to_excel('new_horaires_fin_df.xlsx', index=False)\n",
    "new_horaires_début_df.to_excel('new_horaires_début_df.xlsx', index=False)\n",
    "\n",
    "# %%\n",
    "def ajuster_plage_horaire(heure):\n",
    "    if pd.notnull(heure):\n",
    "        # Extraire la date et l'heure de la cellule\n",
    "        date, time = str(heure).split(' ')\n",
    "        heure, minute, seconde = map(int, time.split(':')[0:3])\n",
    "        \n",
    "        # Calculer la plage horaire correspondante\n",
    "        plage_horaire = f\"{heure:02d}:00:00 - {(heure+1)%24:02d}:00:00\"\n",
    "        \n",
    "        # Construire la date avec la plage horaire\n",
    "        return f\"{date} {plage_horaire}\"\n",
    "    \n",
    "    return heure\n",
    "\n",
    "# Appliquer la fonction à toutes les colonnes (sauf la première)\n",
    "new_horaires_début_df.iloc[:, 1:] = new_horaires_début_df.iloc[:, 1:].map(ajuster_plage_horaire)\n",
    "new_horaires_fin_df.iloc[:, 1:] = new_horaires_fin_df.iloc[:, 1:].map(ajuster_plage_horaire)\n",
    "\n",
    "display(new_horaires_début_df)\n",
    "display(new_horaires_fin_df)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# Ajout du script Nb de personnes + Arrêts + Lignes des lieux des événements\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# %% [markdown]\n",
    "# Liste des lieux et url \n",
    "\n",
    "# %%\n",
    "\n",
    "lieux = [\n",
    "'stade-tour-eiffel',\n",
    "'arena-champ-de-mars',\n",
    "'grand-palais',\n",
    "'invalides',\n",
    "'pont-alexandre-iii',\n",
    "'trocadero', \n",
    "'concorde',\n",
    "'stade-roland-garros',\n",
    "'arena-paris-sud', \n",
    "'arena-bercy', \n",
    "'arena-la-chapelle', \n",
    "'paris-la-defense-arena', \n",
    "'centre-aquatique', \n",
    "'stade-de-france',\n",
    "'site-escalade-bourget',\n",
    "'arena-paris-nord'\n",
    "]\n",
    "\n",
    "urls = [\n",
    "    f\"https://www.paris2024.org/fr/site/{lieu.replace(' ', '-').lower()}/\" for lieu in lieux\n",
    "]\n",
    "\n",
    "# %%\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_specific_lines(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        specific_lines = {\n",
    "            'Capacité': [],\n",
    "            'Stations': []  # Création d'une liste pour stocker les stations\n",
    "        }\n",
    "        for paragraph in soup.find_all('p'):\n",
    "            # Recherche des lignes contenant les Capacité spécifiques\n",
    "            if ('Capacité' in paragraph.text or \n",
    "                'Capacité court Philippe-Chatrier' in paragraph.text or \n",
    "                'Volleyball' in paragraph.text or \n",
    "                'Pour la gymnastique rythmique' in paragraph.text):\n",
    "                specific_lines['Capacité'].append(paragraph.text.strip())\n",
    "                \n",
    "            # Extraction des phrases après \"desservie\" ou \"desservi\"\n",
    "            if 'desservie' in paragraph.text or 'desservi' in paragraph.text:\n",
    "                sentences = paragraph.text.split('.')  # Séparation en phrases\n",
    "                for sentence in sentences:\n",
    "                    if 'desservie' in sentence or 'desservi' in sentence:\n",
    "                        specific_lines['Stations'].append(sentence.strip())\n",
    "        \n",
    "        return specific_lines\n",
    "    return None\n",
    "\n",
    "\n",
    "# Création d'un dictionnaire pour stocker les résultats\n",
    "results = {lieu: get_specific_lines(url) for lieu, url in zip(lieux, urls)}\n",
    "\n",
    "# Création d'un DataFrame à partir du dictionnaire\n",
    "df = pd.DataFrame(results.items(), columns=['Lieu', 'Infos'])\n",
    "# Expansion du dictionnaire pour créer les colonnes 'Capacité' et 'Stations'\n",
    "df = pd.concat([df.drop(['Infos'], axis=1), df['Infos'].apply(pd.Series)], axis=1)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# Compléter pour les données manquantes : Concorde \n",
    "\n",
    "# %%\n",
    "# Faites une requête GET pour récupérer le contenu HTML de la page\n",
    "url = 'https://sportetsociete.org/2022/10/20/paris-2024-un-cadre-majestueux-pour-louverture-des-jeux-paralympiques/#:~:text=Des%20tribunes%20de%2035%20000,des%20Champs%2DÉlysées%20pour%20saluer'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Vérifiez si la requête a réussi\n",
    "if response.status_code == 200:\n",
    "    # Utilisation de BeautifulSoup pour analyser le contenu HTML\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Recherchez le texte contenant \"places\"\n",
    "    texte_places = soup.find(text=lambda text: text and \"places\" in text)\n",
    "\n",
    "    if texte_places:\n",
    "        # Imprimez le texte trouvé\n",
    "        df.iloc[6, 1]=texte_places.strip()\n",
    "\n",
    "# %% [markdown]\n",
    "# Compléter pour les données manquantes : Arena Paris Sud\n",
    "\n",
    "# %%\n",
    "#Compléter pour les valeurs manquantes : arena-paris-sud\n",
    "url = \"https://fr.wikipedia.org/wiki/Arena_Porte_de_la_Chapelle\"\n",
    "\n",
    "# Obtenir le contenu de la page\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Analyser le contenu HTML avec BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Trouver le texte de la ligne commençant par \"Capacité\"\n",
    "    capacity_text = soup.find(\"th\", text=\"Capacité\").find_next(\"td\").get_text(strip=True)\n",
    "\n",
    "    # Mettre à jour la case correspondante dans le DataFrame df\n",
    "    df.iloc[8, 1] = capacity_text  # Ligne 8, colonne 2, indexées à partir de 0\n",
    "\n",
    "else:\n",
    "    print(\"La requête a échoué\")\n",
    "\n",
    "# %%\n",
    "def extraire_nombres(texte):\n",
    "    nombres = re.findall(r'[-+]?\\d*\\.\\d+|\\d+', str(texte))  # Expression régulière pour les nombres entiers ou décimaux\n",
    "    return ' '.join(nombres)  # Retourne les nombres extraits sous forme d'une chaîne séparée par des espaces\n",
    "\n",
    "# Appliquer la fonction sur la colonne 'Capacité'\n",
    "df['Nombre de personnes à l\\'événément'] = df['Capacité'].apply(extraire_nombres)\n",
    "\n",
    "# Supposons que 'df' est votre DataFrame contenant la colonne 'Nombres'\n",
    "\n",
    "# Remplacer \"202\" par une chaîne vide dans la colonne 'Nombre de personnes à l\\'événément'\n",
    "df['Nombre de personnes à l\\'événément'] = df['Nombre de personnes à l\\'événément'].str.replace('202', '')\n",
    "\n",
    "# Supprimer les espaces dans la colonne 'NNombre de personnes à l\\'événément'\n",
    "df['Nombre de personnes à l\\'événément'] = df['Nombre de personnes à l\\'événément'].str.replace(' ', '')\n",
    "\n",
    "# Supposons que 'df' est votre DataFrame contenant la colonne 'Nombres'\n",
    "\n",
    "# Remplacer les valeurs dans la colonne 'Nombres' aux lignes spécifiques\n",
    "df.loc[2, 'Nombre de personnes à l\\'événément'] = '8000'  # Remplacer la deuxième ligne par '8000'\n",
    "df.loc[10, 'Nombre de personnes à l\\'événément'] = '6700'  # Remplacer la 10ème ligne par '6700'\n",
    "df.loc[14, 'Nombre de personnes à l\\'événément'] = '6000'  # Remplacer la 14ème ligne par '6000'\n",
    "\n",
    "# Fonction pour supprimer le zéro en tête des nombres\n",
    "def remove_leading_zero(number):\n",
    "    if number.startswith('0'):\n",
    "        return number[1:]\n",
    "    return number\n",
    "\n",
    "# Appliquer la fonction à la colonne 'Nombres' pour supprimer les zéros en tête\n",
    "df['Nombre de personnes à l\\'événément'] = df['Nombre de personnes à l\\'événément'].astype(str).apply(remove_leading_zero)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Boucle pour lire chaque ligne de la colonne 'Stations'\n",
    "for index, station in df['Stations'].items():\n",
    "    print(station)\n",
    "\n",
    "# %%\n",
    "arrêts=[['BIR HAKEIM', 'ALMA MARCEAU'],\n",
    "        ['LA MOTTE-PICQUET-GRENELLE', 'LA MOTTE-PICQUET-GRENELLE', 'SEGUR'], \n",
    "        ['FRANKLIN D. ROOSEVELT', 'FRANKLIN D. ROOSEVELT'], \n",
    "        ['INVALIDES'], \n",
    "        ['INVALIDES'],\n",
    "        ['IENA','TROCADERO'], \n",
    "        ['PALAIS-ROYAL','PALAIS-ROYAL','MADELEINE', 'MADELEINE', 'MADELEINE', 'OPERA'],\n",
    "        ['PORTE DE SAINT-CLOUD','PORTE D\\'AUTEUIL'], \n",
    "        ['PORTE DE VERSAILLES','BALARD','PORTE DE VANVES'], \n",
    "        ['BERCY','BERCY','GARE DE LYON'],\n",
    "        ['PORTE DE LA CHAPELLE'],\n",
    "        ['LA DEFENSE'],\n",
    "        ['x'],\n",
    "        ['SAINT-DENIS-PORTE DE PARIS'], \n",
    "        ['x'],\n",
    "        ['x']]\n",
    " \n",
    "df['Arrêts']=arrêts\n",
    "\n",
    "# Fonction pour extraire les nombres après le mot \"Métro\"\n",
    "def extract_numbers(text):\n",
    "    matches = re.findall(r'Métro\\s+(\\d+)', str(text), flags=re.IGNORECASE)\n",
    "    return matches\n",
    "\n",
    "# Appliquer la fonction à la colonne 'Stations' pour créer une nouvelle colonne 'Nombres après Métro'\n",
    "df['Lignes'] = df['Stations'].apply(extract_numbers)\n",
    "\n",
    "# Compléter pour Franklin D\n",
    "df.at[2, 'Lignes'] = [6, 9]\n",
    "\n",
    "# %%\n",
    "# Supprimer les colonnes 'Capacité' et 'Stations'\n",
    "colonnes_a_supprimer = ['Capacité', 'Stations']\n",
    "df = df.drop(colonnes_a_supprimer, axis=1)\n",
    "\n",
    "# Calculer le nombre d'éléments dans chaque vecteur de la ligne 'Lignes'\n",
    "df['Nombre de lignes'] = df['Lignes'].apply(lambda x: len(x) if isinstance(x, list) else None)\n",
    "\n",
    "# Convertir la colonne 'Nombre de personnes à l\\'événément' en type numérique (int ou float)\n",
    "df['Nombre de personnes à l\\'événément'] = pd.to_numeric(df['Nombre de personnes à l\\'événément'], errors='coerce')\n",
    "\n",
    "# Créer la nouvelle colonne en calculant la division\n",
    "df['Nombre de personnes par ligne'] = df['Nombre de personnes à l\\'événément'] / df['Nombre de lignes']\n",
    "\n",
    "# Définir l'option d'affichage pour éviter la notation scientifique\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# %%\n",
    "# Identifier les indices des lignes contenant les valeurs spécifiques dans la colonne 'lieu'\n",
    "indices_a_supprimer = df[df['Lieu'].isin(['centre-aquatique', 'site-escalade-bourget', 'arena-paris-nord'])].index\n",
    "\n",
    "# Supprimer les lignes correspondantes\n",
    "df = df.drop(indices_a_supprimer)\n",
    "\n",
    "display(df)\n",
    "\n",
    "df.to_excel('df.xlsx', index=False)\n",
    "\n",
    "# %% [markdown]\n",
    "# Copie du programme fréquentation_metro\n",
    "\n",
    "# %%\n",
    "# Copie du programme Nettoyage données affluence par jour + nombre de validation par jour par station\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "%config NotebookApp.iopub_data_rate_limit=100000000000.0\n",
    "url = '/workspaces/metro-JO/Données importées/2022_S2_PROFIL_FER.csv'\n",
    "données_validation = pd.read_csv(url, delimiter=';')\n",
    "\n",
    "# %%\n",
    "# Convertir la colonne 'pourc_validations' en float (remplacer la virgule par un point pour séparer les décimales)\n",
    "données_validation['pourc_validations'] = données_validation['pourc_validations'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Grouper par 'LIBELLE_ARRET' et 'TRNC_HORR_60', puis calculer la somme des pourc_validations pour chaque groupe\n",
    "tableau_somme_pour_validations = données_validation.groupby(['LIBELLE_ARRET', 'TRNC_HORR_60'])['pourc_validations'].sum().reset_index()\n",
    "\n",
    "\n",
    "# %%\n",
    "# Mapping des tranches horaires à des heures spécifiques\n",
    "tranche_horaire_to_hour = {\n",
    "    '0H-1H': '00:00-01:00',\n",
    "    '1H-2H': '01:00-02:00',\n",
    "    '2H-3H': '02:00-03:00',\n",
    "    '3H-4H': '03:00-04:00',\n",
    "    '4H-5H': '04:00-05:00',\n",
    "    '5H-6H': '05:00-06:00',\n",
    "    '6H-7H': '06:00-07:00',\n",
    "    '7H-8H': '07:00-08:00',\n",
    "    '8H-9H': '08:00-09:00',\n",
    "    '9H-10H': '09:00-10:00',\n",
    "    '10H-11H': '10:00-11:00',\n",
    "    '11H-12H': '11:00-12:00',\n",
    "    '12H-13H': '12:00-13:00',\n",
    "    '13H-14H': '13:00-14:00',\n",
    "    '14H-15H': '14:00-15:00',\n",
    "    '15H-16H': '15:00-16:00',\n",
    "    '16H-17H': '16:00-17:00',\n",
    "    '17H-18H': '17:00-18:00',\n",
    "    '18H-19H': '18:00-19:00',\n",
    "    '19H-20H': '19:00-20:00',\n",
    "    '20H-21H': '20:00-21:00',\n",
    "    '21H-22H': '21:00-22:00',\n",
    "    '22H-23H': '22:00-23:00',\n",
    "    '23H-24H': '23:00-00:00'\n",
    "}\n",
    "\n",
    "# Appliquer la conversion des tranches horaires au format heure\n",
    "tableau_somme_pour_validations['TRNC_HORR_60'] = tableau_somme_pour_validations['TRNC_HORR_60'].map(tranche_horaire_to_hour)\n",
    "\n",
    "# %%\n",
    "# Regroupement des données en cas de doublons pour une paire 'LIBELLE_ARRET'-'TRNC_HORR_60'\n",
    "grouped_data = données_validation.groupby(['LIBELLE_ARRET', 'TRNC_HORR_60'])['pourc_validations'].sum().reset_index()\n",
    "\n",
    "# Pivotement des données\n",
    "pivot_table = grouped_data.pivot(index='LIBELLE_ARRET', columns='TRNC_HORR_60', values='pourc_validations').reset_index()\n",
    "\n",
    "# Renommage des colonnes\n",
    "pivot_table.columns.name = None  # Supprimer le nom de la colonne index\n",
    "pivot_table = pivot_table.rename(columns=lambda x: f\"{x}\" if x != 'LIBELLE_ARRET' else x)\n",
    "\n",
    "# %%\n",
    "import re\n",
    "\n",
    "# Sélectionner les colonnes correspondant aux tranches horaires\n",
    "horaire_columns = pivot_table.columns[1:]  # Exclure la colonne 'LIBELLE_ARRET'\n",
    "\n",
    "# Fonction pour extraire l'heure de début de chaque tranche horaire\n",
    "def extract_start_hour(column):\n",
    "    match = re.match(r'(\\d+)H-(\\d+)H', column)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 0\n",
    "\n",
    "# Trier les colonnes dans l'ordre croissant des heures de début des tranches\n",
    "sorted_columns = sorted(horaire_columns, key=extract_start_hour)\n",
    "\n",
    "# Réorganiser le tableau pivoté avec les colonnes dans l'ordre chronologique\n",
    "new_column_order = ['LIBELLE_ARRET'] + sorted_columns\n",
    "pivot_table = pivot_table[new_column_order]\n",
    "\n",
    "# Supprimer la colonne 'ND' du DataFrame pivot_table_ordered\n",
    "pivot_table.drop(columns=['ND'], inplace=True, errors='ignore')\n",
    "\n",
    "pivot_table['LIBELLE_ARRET'] = pivot_table['LIBELLE_ARRET'].str.strip()  # Supprime les espaces en début et fin\n",
    "pivot_table['LIBELLE_ARRET'] = pivot_table['LIBELLE_ARRET'].str.lower()  # Met tout en minuscules\n",
    "\n",
    "# Créer un dictionnaire de correspondance pour renommer les colonnes\n",
    "correspondance_heures = {\n",
    "    '0H-1H': '00:00-01:00', '1H-2H': '01:00-02:00', '2H-3H': '02:00-03:00', '3H-4H': '03:00-04:00',\n",
    "    '4H-5H': '04:00-05:00', '5H-6H': '05:00-06:00', '6H-7H': '06:00-07:00', '7H-8H': '07:00-08:00',\n",
    "    '8H-9H': '08:00-09:00', '9H-10H': '09:00-10:00', '10H-11H': '10:00-11:00', '11H-12H': '11:00-12:00',\n",
    "    '12H-13H': '12:00-13:00', '13H-14H': '13:00-14:00', '14H-15H': '14:00-15:00', '15H-16H': '15:00-16:00',\n",
    "    '16H-17H': '16:00-17:00', '17H-18H': '17:00-18:00', '18H-19H': '18:00-19:00', '19H-20H': '19:00-20:00',\n",
    "    '20H-21H': '20:00-21:00', '21H-22H': '21:00-22:00', '22H-23H': '22:00-23:00', '23H-0H': '23:00-00:00'\n",
    "}\n",
    "\n",
    "# Renommer les colonnes en utilisant le dictionnaire de correspondance\n",
    "pivot_table.rename(columns=correspondance_heures, inplace=True)\n",
    "\n",
    "# Afficher le DataFrame après suppression de la colonne 'ND'\n",
    "print(pivot_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
