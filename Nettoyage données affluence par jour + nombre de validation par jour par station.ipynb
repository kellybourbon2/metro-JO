{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76abe6a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trnc_horr_60    libelle_arret   0H-1H  10H-11H  11H-12H  12H-13H  13H-14H  \\\n",
      "0                    ABBESSES  1.9100    3.792    4.776    5.672    6.022   \n",
      "1                       ABLON  0.0375    5.314    5.110    5.018    4.816   \n",
      "2               ACHERES GRAND  0.1200    4.506    5.692    5.470    6.676   \n",
      "3               ACHERES VILLE  0.2100    5.934    6.148    6.384    6.170   \n",
      "4               AEROPORT CDG1  0.1260    4.102    4.486    5.208    6.560   \n",
      "..                        ...     ...      ...      ...      ...      ...   \n",
      "742                    VOSVES     NaN    4.360    4.218    9.368    4.512   \n",
      "743           VULAINES SUR SE     NaN    7.312    4.808    5.806    6.052   \n",
      "744                    WAGRAM  0.7640    5.088    5.930    6.988    6.962   \n",
      "745                    YERRES  0.1200    6.058    6.192    5.880    5.788   \n",
      "746            YVRIS NOISY GD  0.0000    4.936    5.674    5.322    5.284   \n",
      "\n",
      "trnc_horr_60  14H-15H  15H-16H  16H-17H  17H-18H  ...    23H-0H     2H-3H  \\\n",
      "0               7.018    8.128    9.012    9.604  ...  3.280000  0.005000   \n",
      "1               4.896    4.850    6.234    6.656  ...  0.360000  0.000000   \n",
      "2               7.096    9.496   10.200    9.838  ...  1.225000       NaN   \n",
      "3               6.146    5.774    6.372    6.670  ...  0.592000  0.016000   \n",
      "4               8.606    8.378    8.096    8.756  ...  1.542000  0.003333   \n",
      "..                ...      ...      ...      ...  ...       ...       ...   \n",
      "742             5.124    5.424    9.010    8.854  ...  0.070000       NaN   \n",
      "743             7.268    5.654    9.360    8.160  ...  0.153333       NaN   \n",
      "744             6.812    7.222    7.812    9.094  ...  1.600000  0.018000   \n",
      "745             5.694    5.250    5.334    5.790  ...  0.368000  0.000000   \n",
      "746             5.684    4.952    5.908    7.168  ...  0.312000       NaN   \n",
      "\n",
      "trnc_horr_60   3H-4H   4H-5H  5H-6H   6H-7H   7H-8H   8H-9H  9H-10H   ND  \n",
      "0             0.0000  0.0000  0.236   0.752   1.884   4.742   4.678  NaN  \n",
      "1             0.0050  0.0820  3.608   7.566  12.040  11.468   7.762  NaN  \n",
      "2                NaN  0.0700  2.234   2.946   5.974   8.830   4.352  NaN  \n",
      "3             0.0260  0.6820  2.354   4.486   9.108  11.440   6.504  0.0  \n",
      "4             0.0025  0.6840  1.584   2.096   3.052   3.516   3.760  NaN  \n",
      "..               ...     ...    ...     ...     ...     ...     ...  ...  \n",
      "742              NaN     NaN  0.930  12.980  18.340   7.424   4.938  NaN  \n",
      "743              NaN     NaN  1.072   3.702   9.026   8.248   5.704  NaN  \n",
      "744           0.0000  0.0025  0.378   0.888   2.342   5.396   5.734  NaN  \n",
      "745           0.0050  0.2400  2.704   6.316  12.012  12.978   6.786  NaN  \n",
      "746              NaN  0.0725  1.832   6.114  12.798  15.318   7.222  NaN  \n",
      "\n",
      "[747 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#Nettoyage de données pour les validations par station et horaires: pour chaque station, on a le pourcentage d'affluence à chaque horaire sur une journée type\n",
    "import pandas as pd\n",
    "%config NotebookApp.iopub_data_rate_limit=100000000000.0\n",
    "url = 'http://opendata.stif.info/explore/dataset/validations-reseau-ferre-profils-horaires-par-jour-type-1er-semestre/download?format=csv&timezone=Europe/Berlin&use_labels_for_header=false'\n",
    "données_validation= pd.read_csv(url)\n",
    "données_validation = pd.read_csv(url, delimiter=';')\n",
    "données_validation_station_horaire = données_validation[['libelle_arret', 'trnc_horr_60','pourc_validations']]\n",
    "donnees_organisees = données_validation_station_horaire.pivot_table(index='libelle_arret', columns='trnc_horr_60', values='pourc_validations', aggfunc='mean').reset_index()\n",
    "print(donnees_organisees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578f678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               jour  code_stif_trns code_stif_res code_stif_arret  \\\n",
      "0        2023-06-26             800           853             568   \n",
      "1        2023-06-26             800           853             568   \n",
      "2        2023-06-26             800           853             568   \n",
      "3        2023-06-26             800           853             568   \n",
      "4        2023-06-26             800           853             595   \n",
      "...             ...             ...           ...             ...   \n",
      "1096204  2023-03-01             100           110             842   \n",
      "1096205  2023-03-01             100           110             848   \n",
      "1096206  2023-03-01             100           110             848   \n",
      "1096207  2023-03-01             100           110             849   \n",
      "1096208  2023-03-01             100           110             850   \n",
      "\n",
      "         libelle_arret    lda categorie_titre  nb_vald  \n",
      "0            MONTSOULT  67000               ?       28  \n",
      "1            MONTSOULT  67000       AMETHYSTE        9  \n",
      "2            MONTSOULT  67000       IMAGINE R      388  \n",
      "3            MONTSOULT  67000             TST      114  \n",
      "4        NOINTEL MOURS  67227               ?        8  \n",
      "...                ...    ...             ...      ...  \n",
      "1096204  SULLY-MORLAND  71201      NON DEFINI      186  \n",
      "1096205     TELEGRAPHE  71870      NON DEFINI      187  \n",
      "1096206     TELEGRAPHE  71870             TST      386  \n",
      "1096207         TEMPLE  71296             TST       95  \n",
      "1096208         TERNES  71367          NAVIGO     4550  \n",
      "\n",
      "[1096209 rows x 8 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'JOUR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'JOUR'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(données_validation2)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#On extrait les données que pour le mois de mai, à défaut d'avoir \u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m données_validation2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJOUR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdonnées_validation2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mJOUR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     12\u001b[0m donnees_mai \u001b[38;5;241m=\u001b[39m données_validation2\u001b[38;5;241m.\u001b[39mloc[(données_validation2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJOUR\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m)]\n\u001b[1;32m     13\u001b[0m donnees_sum \u001b[38;5;241m=\u001b[39m donnees_mai\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIBELLE_ARRET\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNB_VALD\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'JOUR'"
     ]
    }
   ],
   "source": [
    "#Nettoyage de données sur le nombre de validations: on obtient le nombre de validation moyen par jour sur 1 mois précis\n",
    "\n",
    "import pandas as pd\n",
    "%config NotebookApp.iopub_data_rate_limit=100000000000.0\n",
    "url2 = 'http://opendata.stif.info/explore/dataset/validations-reseau-ferre-nombre-validations-par-jour-1er-semestre/download?format=csv&timezone=Europe/Berlin&use_labels_for_header=false'\n",
    "données_validation2= pd.read_csv(url2)\n",
    "données_validation2 = pd.read_csv(url2, delimiter=';')\n",
    "print(données_validation2)\n",
    "\n",
    "#On extrait les données que pour le mois de mai, à défaut d'avoir \n",
    "données_validation2['JOUR'] = pd.to_datetime(données_validation2['JOUR'])\n",
    "donnees_mai = données_validation2.loc[(données_validation2['JOUR'].dt.month == 5)]\n",
    "donnees_sum = donnees_mai.groupby('LIBELLE_ARRET')['NB_VALD'].mean().reset_index()\n",
    "print(donnees_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
